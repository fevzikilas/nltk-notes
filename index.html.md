# Natural Language Processing with NLTK


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Setup

First, let’s install and import NLTK and download the necessary
resources.

``` python
! pip install nltk
```

    Requirement already satisfied: nltk in c:\users\fevzikilas\desktop\nlp\nlp-l\lib\site-packages (3.9.1)
    Requirement already satisfied: click in c:\users\fevzikilas\desktop\nlp\nlp-l\lib\site-packages (from nltk) (8.1.8)
    Requirement already satisfied: joblib in c:\users\fevzikilas\desktop\nlp\nlp-l\lib\site-packages (from nltk) (1.4.2)
    Requirement already satisfied: regex>=2021.8.3 in c:\users\fevzikilas\desktop\nlp\nlp-l\lib\site-packages (from nltk) (2024.11.6)
    Requirement already satisfied: tqdm in c:\users\fevzikilas\desktop\nlp\nlp-l\lib\site-packages (from nltk) (4.67.1)
    Requirement already satisfied: colorama in c:\users\fevzikilas\desktop\nlp\nlp-l\lib\site-packages (from click->nltk) (0.4.6)


    [notice] A new release of pip is available: 24.2 -> 25.0.1
    [notice] To update, run: python.exe -m pip install --upgrade pip

``` python
import nltk
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display, HTML

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
```

    [nltk_data] Downloading package punkt to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Unzipping tokenizers\punkt.zip.
    [nltk_data] Downloading package stopwords to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package stopwords is already up-to-date!
    [nltk_data] Downloading package wordnet to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Unzipping tokenizers\punkt.zip.
    [nltk_data] Downloading package stopwords to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package stopwords is already up-to-date!
    [nltk_data] Downloading package wordnet to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package wordnet is already up-to-date!
    [nltk_data] Downloading package averaged_perceptron_tagger to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package wordnet is already up-to-date!
    [nltk_data] Downloading package averaged_perceptron_tagger to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Unzipping taggers\averaged_perceptron_tagger.zip.
    [nltk_data] Downloading package maxent_ne_chunker to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package maxent_ne_chunker is already up-to-date!
    [nltk_data] Downloading package words to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package words is already up-to-date!
    [nltk_data]   Unzipping taggers\averaged_perceptron_tagger.zip.
    [nltk_data] Downloading package maxent_ne_chunker to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package maxent_ne_chunker is already up-to-date!
    [nltk_data] Downloading package words to
    [nltk_data]     C:\Users\fevzikilas\AppData\Roaming\nltk_data...
    [nltk_data]   Package words is already up-to-date!

    True

## Sample Text Data

Let’s create a sample corpus to work with throughout this notebook.

``` python
corpus = """This is a sample text corpus.
It contains multiple sentences.
The purpose of this corpus is to demonstrate text processing.
"""
```

``` python
# Display the corpus
print("Sample corpus:")
corpus
```

    Sample corpus:

    'This is a sample text corpus.\nIt contains multiple sentences.\nThe purpose of this corpus is to demonstrate text processing.\n'

## Tokenization <a id="tokenization"></a>

Tokenization is the process of breaking down text into smaller units,
such as sentences or words. This is typically the first step in any NLP
pipeline.

### Sentence Tokenization

Sentence tokenization splits a paragraph or document into individual
sentences.

``` python
from nltk.tokenize import sent_tokenize

# Tokenize corpus into sentences
sentences = sent_tokenize(corpus)

print(f"Number of sentences: {len(sentences)}")
for i, sentence in enumerate(sentences, 1):
    print(f"Sentence {i}: {sentence}")
```

    Number of sentences: 3
    Sentence 1: This is a sample text corpus.
    Sentence 2: It contains multiple sentences.
    Sentence 3: The purpose of this corpus is to demonstrate text processing.

``` python
# Check type of document
print(f"Type of tokenized sentences: {type(sentences)}")
```

    Type of tokenized sentences: <class 'list'>

### Word Tokenization

Word tokenization splits sentences into individual words. NLTK offers
several tokenizers with different behaviors.

``` python
# Word tokenization (sentence → words)
from nltk.tokenize import word_tokenize

# Tokenize each sentence into words
print("Word tokenization results:")
for i, sentence in enumerate(sentences, 1):
    words = word_tokenize(sentence)
    print(f"Sentence {i}: {words}")
```

    Word tokenization results:
    Sentence 1: ['This', 'is', 'a', 'sample', 'text', 'corpus', '.']
    Sentence 2: ['It', 'contains', 'multiple', 'sentences', '.']
    Sentence 3: ['The', 'purpose', 'of', 'this', 'corpus', 'is', 'to', 'demonstrate', 'text', 'processing', '.']

### Comparing Different Tokenizers

NLTK provides various tokenizers, each with different rules and
behaviors. Let’s compare them:

``` python
from nltk.tokenize import wordpunct_tokenize, TreebankWordTokenizer
import pandas as pd 
# Sample text for comparison
sample = "Don't hesitate to email me at john.doe@example.com or call at 555-123-4567!"

# Compare different tokenizers
tokenizers = {
    'word_tokenize': word_tokenize,
    'wordpunct_tokenize': wordpunct_tokenize,
    'TreebankWordTokenizer': TreebankWordTokenizer().tokenize
}

# Create a DataFrame to display results
results = {}
max_length = 0

# Tokenize and find the maximum length of tokenized results
for name, tokenizer in tokenizers.items():
    tokenized = tokenizer(sample)
    results[name] = tokenized
    max_length = max(max_length, len(tokenized))

# Pad tokenized results to make all arrays the same length
for name in results:
    results[name] += [None] * (max_length - len(results[name]))

# Display results as a DataFrame
pd.DataFrame(results).T
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
<th data-quarto-table-cell-role="th">6</th>
<th data-quarto-table-cell-role="th">7</th>
<th data-quarto-table-cell-role="th">8</th>
<th data-quarto-table-cell-role="th">9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">14</th>
<th data-quarto-table-cell-role="th">15</th>
<th data-quarto-table-cell-role="th">16</th>
<th data-quarto-table-cell-role="th">17</th>
<th data-quarto-table-cell-role="th">18</th>
<th data-quarto-table-cell-role="th">19</th>
<th data-quarto-table-cell-role="th">20</th>
<th data-quarto-table-cell-role="th">21</th>
<th data-quarto-table-cell-role="th">22</th>
<th data-quarto-table-cell-role="th">23</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">word_tokenize</td>
<td>Do</td>
<td>n't</td>
<td>hesitate</td>
<td>to</td>
<td>email</td>
<td>me</td>
<td>at</td>
<td>john.doe</td>
<td>@</td>
<td>example.com</td>
<td>...</td>
<td>!</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">wordpunct_tokenize</td>
<td>Don</td>
<td>'</td>
<td>t</td>
<td>hesitate</td>
<td>to</td>
<td>email</td>
<td>me</td>
<td>at</td>
<td>john</td>
<td>.</td>
<td>...</td>
<td>com</td>
<td>or</td>
<td>call</td>
<td>at</td>
<td>555</td>
<td>-</td>
<td>123</td>
<td>-</td>
<td>4567</td>
<td>!</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">TreebankWordTokenizer</td>
<td>Do</td>
<td>n't</td>
<td>hesitate</td>
<td>to</td>
<td>email</td>
<td>me</td>
<td>at</td>
<td>john.doe</td>
<td>@</td>
<td>example.com</td>
<td>...</td>
<td>!</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>

<p>3 rows × 24 columns</p>
</div>

## Stemming <a id="stemming"></a>

Stemming is the process of reducing words to their word stem or root
form. It’s a rule-based process that chops off the ends of words to
remove affixes. Stemming is useful for text normalization, but often
produces non-dictionary words.

### Comparing Different Stemmers

``` python
from nltk.stem import PorterStemmer, RegexpStemmer, SnowballStemmer

# Create sample words to compare stemmers
words = ["fearly", "running", "ran", "easily", "fairness", "eating", "eats", "eater", "eat", "history", "historical", "congratulations", "sliding", "comfortable"]
```

``` python
import pandas as pd 
# Initialize stemmers
porter_stemmer = PorterStemmer()
regexp_stemmer = RegexpStemmer('ing$|s$|e$|able', min=4)
snowball_stemmer = SnowballStemmer(language="english")

# Create comparison table
stemming_results = {
    'Original': words,
    'Porter': [porter_stemmer.stem(word) for word in words],
    'RegExp': [regexp_stemmer.stem(word) for word in words],
    'Snowball': [snowball_stemmer.stem(word) for word in words]
}

# Display results
stemming_df = pd.DataFrame(stemming_results)
stemming_df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Original</th>
<th data-quarto-table-cell-role="th">Porter</th>
<th data-quarto-table-cell-role="th">RegExp</th>
<th data-quarto-table-cell-role="th">Snowball</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>fearly</td>
<td>fearli</td>
<td>fearly</td>
<td>fear</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>running</td>
<td>run</td>
<td>runn</td>
<td>run</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>ran</td>
<td>ran</td>
<td>ran</td>
<td>ran</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>easily</td>
<td>easili</td>
<td>easily</td>
<td>easili</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>fairness</td>
<td>fair</td>
<td>fairnes</td>
<td>fair</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>eating</td>
<td>eat</td>
<td>eat</td>
<td>eat</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>eats</td>
<td>eat</td>
<td>eat</td>
<td>eat</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">7</td>
<td>eater</td>
<td>eater</td>
<td>eater</td>
<td>eater</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">8</td>
<td>eat</td>
<td>eat</td>
<td>eat</td>
<td>eat</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9</td>
<td>history</td>
<td>histori</td>
<td>history</td>
<td>histori</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">10</td>
<td>historical</td>
<td>histor</td>
<td>historical</td>
<td>histor</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">11</td>
<td>congratulations</td>
<td>congratul</td>
<td>congratulation</td>
<td>congratul</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">12</td>
<td>sliding</td>
<td>slide</td>
<td>slid</td>
<td>slide</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">13</td>
<td>comfortable</td>
<td>comfort</td>
<td>comfort</td>
<td>comfort</td>
</tr>
</tbody>
</table>

</div>

### Stemming Analysis

As you can see from the results:

1.  **Porter Stemmer**: One of the oldest and simplest stemmers, it
    applies a set of rules to remove suffixes.
2.  **RegExp Stemmer**: Uses regular expressions to strip specified
    patterns from the end of words. It’s simple but less comprehensive.
3.  **Snowball Stemmer**: An improved version of the Porter algorithm,
    also known as Porter2, offering better accuracy for English and
    support for multiple languages.

Notice how stemming can sometimes produce non-dictionary words (e.g.,
“histori” for “history”). This is one of the main drawbacks of stemming
compared to lemmatization.

## Lemmatization <a id="lemmatization"></a>

Lemmatization is similar to stemming, but it reduces words to their
dictionary form (lemma) rather than just chopping off affixes. It
considers the morphological analysis of the words and produces actual
dictionary words.

Lemmatization is often preferred for applications like chatbots, Q&A
systems, and text summarization because it preserves the meaning of
words.

``` python
from nltk.stem import WordNetLemmatizer

# Initialize the WordNet Lemmatizer
lemmatizer = WordNetLemmatizer()
```

``` python
import pandas as pd
# Lemmatization with different POS (Part-of-Speech) tags
# POS tags: n-noun, v-verb, a-adjective, r-adverb
pos_tags = {'n': 'noun', 'v': 'verb', 'a': 'adjective', 'r': 'adverb'}

# Test words for lemmatization
lemma_words = ["running", "ran", "better", "studies", "studied", "feet", "children", "geese", "mice", "are", "is", "was", "fairly"]

# Create comparison table for different POS tags
lemma_results = {'Original': lemma_words}

for pos_tag, name in pos_tags.items():
    lemma_results[f'Lemma ({name})'] = [lemmatizer.lemmatize(word, pos=pos_tag) for word in lemma_words]

# Display results
pd.DataFrame(lemma_results)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Original</th>
<th data-quarto-table-cell-role="th">Lemma (noun)</th>
<th data-quarto-table-cell-role="th">Lemma (verb)</th>
<th data-quarto-table-cell-role="th">Lemma (adjective)</th>
<th data-quarto-table-cell-role="th">Lemma (adverb)</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>running</td>
<td>running</td>
<td>run</td>
<td>running</td>
<td>running</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>ran</td>
<td>ran</td>
<td>run</td>
<td>ran</td>
<td>ran</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>better</td>
<td>better</td>
<td>better</td>
<td>good</td>
<td>well</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>studies</td>
<td>study</td>
<td>study</td>
<td>studies</td>
<td>studies</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>studied</td>
<td>studied</td>
<td>study</td>
<td>studied</td>
<td>studied</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>feet</td>
<td>foot</td>
<td>feet</td>
<td>feet</td>
<td>feet</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>children</td>
<td>child</td>
<td>children</td>
<td>children</td>
<td>children</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">7</td>
<td>geese</td>
<td>goose</td>
<td>geese</td>
<td>geese</td>
<td>geese</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">8</td>
<td>mice</td>
<td>mouse</td>
<td>mice</td>
<td>mice</td>
<td>mice</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9</td>
<td>are</td>
<td>are</td>
<td>be</td>
<td>are</td>
<td>are</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">10</td>
<td>is</td>
<td>is</td>
<td>be</td>
<td>is</td>
<td>is</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">11</td>
<td>was</td>
<td>wa</td>
<td>be</td>
<td>was</td>
<td>was</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">12</td>
<td>fairly</td>
<td>fairly</td>
<td>fairly</td>
<td>fairly</td>
<td>fairly</td>
</tr>
</tbody>
</table>

</div>

### Stemming vs. Lemmatization

Let’s compare stemming and lemmatization side by side to see the
differences:

``` python
# Compare stemming vs lemmatization
compare_words = ["running", "better", "studies", "feet", "wolves", "are", "historically"]

comparison = {
    'Original': compare_words,
    'Porter Stemmer': [porter_stemmer.stem(word) for word in compare_words],
    'Snowball Stemmer': [snowball_stemmer.stem(word) for word in compare_words],
    'Lemmatization (verb)': [lemmatizer.lemmatize(word, pos='v') for word in compare_words],
    'Lemmatization (noun)': [lemmatizer.lemmatize(word, pos='n') for word in compare_words]
}

pd.DataFrame(comparison)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Original</th>
<th data-quarto-table-cell-role="th">Porter Stemmer</th>
<th data-quarto-table-cell-role="th">Snowball Stemmer</th>
<th data-quarto-table-cell-role="th">Lemmatization (verb)</th>
<th data-quarto-table-cell-role="th">Lemmatization (noun)</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>running</td>
<td>run</td>
<td>run</td>
<td>run</td>
<td>running</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>better</td>
<td>better</td>
<td>better</td>
<td>better</td>
<td>better</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>studies</td>
<td>studi</td>
<td>studi</td>
<td>study</td>
<td>study</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>feet</td>
<td>feet</td>
<td>feet</td>
<td>feet</td>
<td>foot</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>wolves</td>
<td>wolv</td>
<td>wolv</td>
<td>wolves</td>
<td>wolf</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>are</td>
<td>are</td>
<td>are</td>
<td>be</td>
<td>are</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>historically</td>
<td>histor</td>
<td>histor</td>
<td>historically</td>
<td>historically</td>
</tr>
</tbody>
</table>

</div>

## Stopword Removal <a id="stopwords"></a>

Stopwords are common words like “the”, “a”, “an”, “in” that usually
don’t carry much meaning in text analysis. Removing them can help reduce
noise in text processing.

``` python
# Sample paragraph for stopword removal
paragraph = """On July 16, 1969, the Apollo 11 spacecraft launched from the Kennedy Space Center in Florida. Its mission was to go where no human being had gone before—the moon! The crew consisted of Neil Armstrong, Michael Collins, and Buzz Aldrin. The spacecraft landed on the moon in the Sea of Tranquility, a basaltic flood plain, on July 20, 1969. The moonwalk took place the following day. On July 21, 1969, at precisely 10:56 EDT, Commander Neil Armstrong emerged from the Lunar Module and took his famous first step onto the moon's surface. He declared, 
 It was a monumental moment in human history!"""
```

``` python
from nltk.corpus import stopwords

# Get English stopwords
stop_words = stopwords.words('english')

# Display first 20 stopwords
print(f"Total English stopwords: {len(stop_words)}")
print(f"Sample stopwords: {stop_words[:20]}")
```

    Total English stopwords: 198
    Sample stopwords: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', "aren't", 'as', 'at', 'be', 'because', 'been']

``` python
# Process text with and without stopwords removal
# Tokenize the paragraph into sentences
sentences = nltk.sent_tokenize(paragraph)

# Initialize lists for processed sentences
with_stopwords = []
without_stopwords = []

# Process each sentence
for sentence in sentences[:3]:  # Process first 3 sentences for brevity
    words = nltk.word_tokenize(sentence)
    
    # Keep all words
    with_stopwords.append(' '.join(words))
    
    # Remove stopwords
    filtered_words = [word for word in words if word.lower() not in stop_words]
    without_stopwords.append(' '.join(filtered_words))

# Create DataFrame for comparison
stopword_df = pd.DataFrame({
    'Original with Stopwords': with_stopwords,
    'After Stopwords Removal': without_stopwords
})

stopword_df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Original with Stopwords</th>
<th data-quarto-table-cell-role="th">After Stopwords Removal</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>On July 16 , 1969 , the Apollo 11 spacecraft l...</td>
<td>July 16 , 1969 , Apollo 11 spacecraft launched...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>Its mission was to go where no human being had...</td>
<td>mission go human gone before—the moon !</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>The crew consisted of Neil Armstrong , Michael...</td>
<td>crew consisted Neil Armstrong , Michael Collin...</td>
</tr>
</tbody>
</table>

</div>

### Complete Text Processing Pipeline

Let’s put everything together to create a complete text processing
pipeline that includes tokenization, stopword removal, and either
stemming or lemmatization.

``` python
def process_text(text, use_stemming=True, use_lemmatization=False):
    """Process text using a complete NLP pipeline
    
    Args:
        text (str): Input text to process
        use_stemming (bool): Whether to apply stemming
        use_lemmatization (bool): Whether to apply lemmatization
        
    Returns:
        list: List of processed sentences
    """
    # Tokenize into sentences
    sentences = nltk.sent_tokenize(text)
    processed_sentences = []
    
    for sentence in sentences:
        # Tokenize into words
        words = nltk.word_tokenize(sentence)
        
        # Remove stopwords
        filtered_words = [word.lower() for word in words if word.lower() not in stopwords.words('english') and word.isalnum()]
        
        # Apply stemming or lemmatization
        if use_stemming:
            processed_words = [snowball_stemmer.stem(word) for word in filtered_words]
        elif use_lemmatization:
            processed_words = [lemmatizer.lemmatize(word, pos='v') for word in filtered_words]
        else:
            processed_words = filtered_words
            
        processed_sentences.append(' '.join(processed_words))
        
    return processed_sentences

# Process the paragraph
stemmed_text = process_text(paragraph, use_stemming=True, use_lemmatization=False)
lemmatized_text = process_text(paragraph, use_stemming=False, use_lemmatization=True)

# Display first 3 processed sentences
for i, (stem, lemma) in enumerate(zip(stemmed_text[:3], lemmatized_text[:3])):
    print(f"Sentence {i+1}:")
    print(f"  Stemmed: {stem}")
    print(f"  Lemmatized: {lemma}")
    print()
```

    Sentence 1:
      Stemmed: juli 16 1969 apollo 11 spacecraft launch kennedi space center florida
      Lemmatized: july 16 1969 apollo 11 spacecraft launch kennedy space center florida

    Sentence 2:
      Stemmed: mission go human gone moon
      Lemmatized: mission go human go moon

    Sentence 3:
      Stemmed: crew consist neil armstrong michael collin buzz aldrin
      Lemmatized: crew consist neil armstrong michael collins buzz aldrin

## Part-of-Speech (POS) Tagging <a id="pos"></a>

POS tagging is the process of marking words in a text with their
corresponding part of speech (noun, verb, adjective, etc.). It’s an
essential step for many NLP applications.

``` python
# Common POS tags in NLTK
pos_tags_info = {
    'CC': 'Coordinating conjunction',
    'CD': 'Cardinal digit',
    'DT': 'Determiner',
    'EX': 'Existential there ("there is")',
    'FW': 'Foreign word',
    'IN': 'Preposition/subordinating conjunction',
    'JJ': 'Adjective',
    'JJR': 'Adjective, comparative ("bigger")',
    'JJS': 'Adjective, superlative ("biggest")',
    'LS': 'List marker',
    'MD': 'Modal (could, will)',
    'NN': 'Noun, singular',
    'NNS': 'Noun plural',
    'NNP': 'Proper noun, singular',
    'NNPS': 'Proper noun, plural',
    'PDT': 'Predeterminer',
    'POS': 'Possessive ending',
    'PRP': 'Personal pronoun (I, he, she)',
    'PRP$': 'Possessive pronoun (my, his, hers)',
    'RB': 'Adverb',
    'RBR': 'Adverb, comparative',
    'RBS': 'Adverb, superlative',
    'RP': 'Particle',
    'TO': 'to',
    'UH': 'Interjection',
    'VB': 'Verb, base form',
    'VBD': 'Verb, past tense',
    'VBG': 'Verb, gerund/present participle',
    'VBN': 'Verb, past participle',
    'VBP': 'Verb, sing. present, non-3d',
    'VBZ': 'Verb, 3rd person sing. present',
    'WDT': 'Wh-determiner (which)',
    'WP': 'Wh-pronoun (who, what)',
    'WP$': 'Possessive wh-pronoun (whose)',
    'WRB': 'Wh-adverb (where, when)'
}

# Display POS tag information as a table
pos_df = pd.DataFrame([(tag, desc) for tag, desc in pos_tags_info.items()], 
                      columns=['Tag', 'Description'])
pos_df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Tag</th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>CC</td>
<td>Coordinating conjunction</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>CD</td>
<td>Cardinal digit</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>DT</td>
<td>Determiner</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>EX</td>
<td>Existential there ("there is")</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>FW</td>
<td>Foreign word</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>IN</td>
<td>Preposition/subordinating conjunction</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>JJ</td>
<td>Adjective</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">7</td>
<td>JJR</td>
<td>Adjective, comparative ("bigger")</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">8</td>
<td>JJS</td>
<td>Adjective, superlative ("biggest")</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9</td>
<td>LS</td>
<td>List marker</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">10</td>
<td>MD</td>
<td>Modal (could, will)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">11</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">12</td>
<td>NNS</td>
<td>Noun plural</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">13</td>
<td>NNP</td>
<td>Proper noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">14</td>
<td>NNPS</td>
<td>Proper noun, plural</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">15</td>
<td>PDT</td>
<td>Predeterminer</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">16</td>
<td>POS</td>
<td>Possessive ending</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">17</td>
<td>PRP</td>
<td>Personal pronoun (I, he, she)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">18</td>
<td>PRP$</td>
<td>Possessive pronoun (my, his, hers)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">19</td>
<td>RB</td>
<td>Adverb</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">20</td>
<td>RBR</td>
<td>Adverb, comparative</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">21</td>
<td>RBS</td>
<td>Adverb, superlative</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">22</td>
<td>RP</td>
<td>Particle</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">23</td>
<td>TO</td>
<td>to</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">24</td>
<td>UH</td>
<td>Interjection</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">25</td>
<td>VB</td>
<td>Verb, base form</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">26</td>
<td>VBD</td>
<td>Verb, past tense</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">27</td>
<td>VBG</td>
<td>Verb, gerund/present participle</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">28</td>
<td>VBN</td>
<td>Verb, past participle</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">29</td>
<td>VBP</td>
<td>Verb, sing. present, non-3d</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">30</td>
<td>VBZ</td>
<td>Verb, 3rd person sing. present</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">31</td>
<td>WDT</td>
<td>Wh-determiner (which)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">32</td>
<td>WP</td>
<td>Wh-pronoun (who, what)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">33</td>
<td>WP$</td>
<td>Possessive wh-pronoun (whose)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">34</td>
<td>WRB</td>
<td>Wh-adverb (where, when)</td>
</tr>
</tbody>
</table>

</div>

``` python
# Example sentences for POS tagging
example_sentences = [
    "The quick brown fox jumps over the lazy dog.",
    "I am studying natural language processing.",
    "She walked to the store, but it was closed."
]

# Perform POS tagging
for i, sentence in enumerate(example_sentences, 1):
    # Tokenize and tag words
    words = nltk.word_tokenize(sentence)
    tagged = nltk.pos_tag(words)
    
    # Create a visualization of the tagged sentence
    print(f"Sentence {i}: {sentence}")
    
    # Display tagged words in a table format
    tagged_df = pd.DataFrame(tagged, columns=['Word', 'POS Tag'])
    tagged_df['Description'] = tagged_df['POS Tag'].map(lambda tag: pos_tags_info.get(tag, 'Unknown'))
    display(tagged_df)
    print("\n")
```

    Sentence 1: The quick brown fox jumps over the lazy dog.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Word</th>
<th data-quarto-table-cell-role="th">POS Tag</th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>The</td>
<td>DT</td>
<td>Determiner</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>quick</td>
<td>JJ</td>
<td>Adjective</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>brown</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>fox</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>jumps</td>
<td>VBZ</td>
<td>Verb, 3rd person sing. present</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>over</td>
<td>IN</td>
<td>Preposition/subordinating conjunction</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>the</td>
<td>DT</td>
<td>Determiner</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">7</td>
<td>lazy</td>
<td>JJ</td>
<td>Adjective</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">8</td>
<td>dog</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9</td>
<td>.</td>
<td>.</td>
<td>Unknown</td>
</tr>
</tbody>
</table>

</div>



    Sentence 2: I am studying natural language processing.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Word</th>
<th data-quarto-table-cell-role="th">POS Tag</th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>I</td>
<td>PRP</td>
<td>Personal pronoun (I, he, she)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>am</td>
<td>VBP</td>
<td>Verb, sing. present, non-3d</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>studying</td>
<td>VBG</td>
<td>Verb, gerund/present participle</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>natural</td>
<td>JJ</td>
<td>Adjective</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>language</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>processing</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>.</td>
<td>.</td>
<td>Unknown</td>
</tr>
</tbody>
</table>

</div>



    Sentence 3: She walked to the store, but it was closed.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Word</th>
<th data-quarto-table-cell-role="th">POS Tag</th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>She</td>
<td>PRP</td>
<td>Personal pronoun (I, he, she)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>walked</td>
<td>VBD</td>
<td>Verb, past tense</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>to</td>
<td>TO</td>
<td>to</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>the</td>
<td>DT</td>
<td>Determiner</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>store</td>
<td>NN</td>
<td>Noun, singular</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>,</td>
<td>,</td>
<td>Unknown</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>but</td>
<td>CC</td>
<td>Coordinating conjunction</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">7</td>
<td>it</td>
<td>PRP</td>
<td>Personal pronoun (I, he, she)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">8</td>
<td>was</td>
<td>VBD</td>
<td>Verb, past tense</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9</td>
<td>closed</td>
<td>VBN</td>
<td>Verb, past participle</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">10</td>
<td>.</td>
<td>.</td>
<td>Unknown</td>
</tr>
</tbody>
</table>

</div>

## Named Entity Recognition (NER) <a id="ner"></a>

Named Entity Recognition is the process of identifying and classifying
named entities in text into predefined categories such as person names,
organizations, locations, time expressions, quantities, etc.

``` python
# Example sentences for NER
ner_examples = [
    "The Eiffel Tower stands on four lattice-girder piers that taper inward and join to form a single large vertical tower.",
    "Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976.",
    "Barack Obama was born in Hawaii and served as the 44th president of the United States from 2009 to 2017."
]
```

``` python
# Process examples with NER
for i, example in enumerate(ner_examples, 1):
    # Tokenize and tag
    words = nltk.word_tokenize(example)
    pos_tags = nltk.pos_tag(words)
    
    # Apply NER
    ner_tree = nltk.ne_chunk(pos_tags)
    
    print(f"Example {i}: {example}")
    print("\nNamed Entities:")
    
    # Extract and print named entities
    named_entities = []
    for chunk in ner_tree:
        if hasattr(chunk, 'label'):
            entity_name = ' '.join(c[0] for c in chunk)
            entity_type = chunk.label()
            named_entities.append((entity_name, entity_type))
    
    if named_entities:
        entities_df = pd.DataFrame(named_entities, columns=['Entity', 'Type'])
        display(entities_df)
    else:
        print("No named entities found")
    
    print("\n")
```

    Example 1: The Eiffel Tower stands on four lattice-girder piers that taper inward and join to form a single large vertical tower.

    Named Entities:

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Entity</th>
<th data-quarto-table-cell-role="th">Type</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>Eiffel Tower</td>
<td>ORGANIZATION</td>
</tr>
</tbody>
</table>

</div>



    Example 2: Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976.

    Named Entities:
    Example 2: Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976.

    Named Entities:

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Entity</th>
<th data-quarto-table-cell-role="th">Type</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>Apple</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>Inc.</td>
<td>ORGANIZATION</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>Steve Jobs</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>Steve Wozniak</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>Ronald Wayne</td>
<td>PERSON</td>
</tr>
</tbody>
</table>

</div>



    Example 3: Barack Obama was born in Hawaii and served as the 44th president of the United States from 2009 to 2017.

    Named Entities:
    Example 3: Barack Obama was born in Hawaii and served as the 44th president of the United States from 2009 to 2017.

    Named Entities:

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Entity</th>
<th data-quarto-table-cell-role="th">Type</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>Barack</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>Obama</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>Hawaii</td>
<td>GPE</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>United States</td>
<td>GPE</td>
</tr>
</tbody>
</table>

</div>

``` python
# Visualize NER Tree (if svgling is installed)
try:
    import svgling
    
    # Use the second example for visualization
    example = ner_examples[1]
    words = nltk.word_tokenize(example)
    pos_tags = nltk.pos_tag(words)
    ner_tree = nltk.ne_chunk(pos_tags)
    
    print(f"Named Entity Tree for: {example}")
    svgling.draw_tree(ner_tree)
except ImportError:
    print("To visualize NER trees, install the 'svgling' package using: pip install svgling")
    # Alternative visualization
    print(ner_tree)
```

    Named Entity Tree for: Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976.

## Text Analysis Dashboard <a id="applications"></a>

Let’s create a comprehensive analysis of text using various NLP
techniques we’ve learned.

``` python
def analyze_text(text):
    """Comprehensive text analysis using NLTK"""
    from collections import Counter
    import re
    
    # Basic statistics
    sentences = nltk.sent_tokenize(text)
    words = nltk.word_tokenize(text)
    words_lower = [word.lower() for word in words if word.isalnum()]
    stop_words = set(stopwords.words('english'))
    words_no_stop = [word for word in words_lower if word not in stop_words]
    
    # Word frequency
    word_freq = Counter(words_no_stop)
    common_words = word_freq.most_common(10)
    
    # POS distribution
    pos_tags = nltk.pos_tag(words_lower)
    pos_counts = Counter([tag for _, tag in pos_tags])
    
    # Named entities
    ner_tree = nltk.ne_chunk(nltk.pos_tag(words))
    named_entities = []
    for chunk in ner_tree:
        if hasattr(chunk, 'label'):
            entity_name = ' '.join(c[0] for c in chunk)
            entity_type = chunk.label()
            named_entities.append((entity_name, entity_type))
    
    # Print results
    print("=== TEXT ANALYSIS DASHBOARD ===")
    print(f"Text length: {len(text)} characters")
    print(f"Sentences: {len(sentences)}")
    print(f"Words: {len(words_lower)}")
    print(f"Unique words: {len(set(words_lower))}")
    print(f"Words without stopwords: {len(words_no_stop)}")
    
    print("\n=== MOST COMMON WORDS ===")
    for word, count in common_words:
        print(f"{word}: {count}")
    
    print("\n=== PART OF SPEECH DISTRIBUTION ===")
    for pos, count in pos_counts.most_common(5):
        print(f"{pos} ({pos_tags_info.get(pos, 'Unknown')}): {count}")
    
    print("\n=== NAMED ENTITIES ===")
    if named_entities:
        entities_df = pd.DataFrame(named_entities, columns=['Entity', 'Type'])
        display(entities_df)
    else:
        print("No named entities found")
    
    # Generate word cloud if matplotlib is available
    try:
        from wordcloud import WordCloud
        
        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(words_no_stop))
        
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title('Word Cloud')
        plt.show()
    except ImportError:
        print("\nInstall wordcloud package for word cloud visualization: pip install wordcloud")

# Run analysis on the Apollo 11 paragraph
analyze_text(paragraph)
```

    === TEXT ANALYSIS DASHBOARD ===
    Text length: 593 characters
    Sentences: 7
    Words: 100
    Unique words: 70
    Words without stopwords: 63

    === MOST COMMON WORDS ===
    july: 3
    1969: 3
    moon: 3
    spacecraft: 2
    human: 2
    neil: 2
    armstrong: 2
    took: 2
    16: 1
    apollo: 1

    === PART OF SPEECH DISTRIBUTION ===
    NN (Noun, singular): 32
    IN (Preposition/subordinating conjunction): 14
    DT (Determiner): 13
    VBD (Verb, past tense): 9
    JJ (Adjective): 8

    === NAMED ENTITIES ===

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Entity</th>
<th data-quarto-table-cell-role="th">Type</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>Kennedy Space Center</td>
<td>FACILITY</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>Florida</td>
<td>GPE</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>Neil Armstrong</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>Michael Collins</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>Buzz Aldrin</td>
<td>PERSON</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">5</td>
<td>Sea</td>
<td>ORGANIZATION</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">6</td>
<td>Tranquility</td>
<td>GPE</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">7</td>
<td>Commander Neil Armstrong</td>
<td>ORGANIZATION</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">8</td>
<td>Lunar Module</td>
<td>ORGANIZATION</td>
</tr>
</tbody>
</table>

</div>


    Install wordcloud package for word cloud visualization: pip install wordcloud
